{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def uni(mu1,mu2,sig1,sig2,p):\n",
    "\n",
    "    d = 0.5*abs(mu1-mu2)/np.sqrt(sig1*sig2)\n",
    "    if d<=1:\n",
    "        return 1\n",
    "    elif abs(np.log(1-p)-np.log(p)) >=2*np.log(d-np.sqrt(d**2-1))+2*d*np.sqrt(d**2-1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Uni= 0.51455\n"
     ]
    }
   ],
   "source": [
    "Nexamples    = 20000\n",
    "Nsamples     = 100\n",
    "Nbins        = 100\n",
    "bin_edges    = np.linspace(-4, 5, Nbins+1)\n",
    "bincenters   = 0.5*(bin_edges[:-1]+bin_edges[1:])\n",
    "histo_counts = np.zeros((Nbins, Nexamples))\n",
    "\n",
    "\n",
    "X = np.zeros((Nsamples, Nexamples))\n",
    "Pars = np.random.uniform(0,1,(5, Nexamples)) # mu1 mu2 sig1 sig2 p1\n",
    "Pars[1,:] = Pars[1,:]+1.2  # mu2+1\n",
    "G = np.random.normal(0,1,(Nsamples, Nexamples))\n",
    "U = np.random.uniform(0,1,(Nsamples, Nexamples))\n",
    "Y = np.zeros(( Nexamples))\n",
    "\n",
    "\n",
    "for i in range(Nexamples):\n",
    "    mu1, mu2, sig1, sig2, p1 = Pars[:,i]\n",
    "    Y[i] = uni(mu1, mu2, sig1, sig2, p1)\n",
    "    r = U[:,i]\n",
    "    mu = mu1*(r<p1) + mu2*(r>=p1)\n",
    "    sig = sig1*(r<p1) + sig2*(r>=p1)\n",
    "    X[:,i] = mu+sig*G[:,1]\n",
    "        \n",
    "    counts, bin_edges = np.histogram(X[:,i], bins=bin_edges, density=  False)\n",
    "    histo_counts[:,i] = counts\n",
    "        \n",
    "\n",
    "print('Mean Uni= '+str(np.mean(Y)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n",
      "(14000, 100)\n",
      "(14000,)\n",
      "Epoch 1/100\n",
      "438/438 [==============================] - 1s 727us/step - loss: 0.5864 - accuracy: 0.7287\n",
      "Epoch 2/100\n",
      "438/438 [==============================] - 0s 841us/step - loss: 0.4445 - accuracy: 0.8059\n",
      "Epoch 3/100\n",
      "438/438 [==============================] - 0s 688us/step - loss: 0.4205 - accuracy: 0.8143\n",
      "Epoch 4/100\n",
      "438/438 [==============================] - 0s 641us/step - loss: 0.3969 - accuracy: 0.8257\n",
      "Epoch 5/100\n",
      "438/438 [==============================] - 0s 643us/step - loss: 0.3804 - accuracy: 0.8401\n",
      "Epoch 6/100\n",
      "438/438 [==============================] - 0s 650us/step - loss: 0.3697 - accuracy: 0.8416\n",
      "Epoch 7/100\n",
      "438/438 [==============================] - 0s 652us/step - loss: 0.3460 - accuracy: 0.8594\n",
      "Epoch 8/100\n",
      "438/438 [==============================] - 0s 645us/step - loss: 0.3407 - accuracy: 0.8625\n",
      "Epoch 9/100\n",
      "438/438 [==============================] - 0s 645us/step - loss: 0.3315 - accuracy: 0.8635\n",
      "Epoch 10/100\n",
      "438/438 [==============================] - 0s 656us/step - loss: 0.3346 - accuracy: 0.8646\n",
      "Epoch 11/100\n",
      "438/438 [==============================] - 0s 728us/step - loss: 0.3153 - accuracy: 0.8719\n",
      "Epoch 12/100\n",
      "438/438 [==============================] - 0s 661us/step - loss: 0.3166 - accuracy: 0.8717\n",
      "Epoch 13/100\n",
      "438/438 [==============================] - 0s 721us/step - loss: 0.3264 - accuracy: 0.8665\n",
      "Epoch 14/100\n",
      "438/438 [==============================] - 0s 703us/step - loss: 0.3090 - accuracy: 0.8740\n",
      "Epoch 15/100\n",
      "438/438 [==============================] - 0s 688us/step - loss: 0.3076 - accuracy: 0.8753\n",
      "Epoch 16/100\n",
      "438/438 [==============================] - 0s 728us/step - loss: 0.3022 - accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "438/438 [==============================] - 0s 954us/step - loss: 0.2998 - accuracy: 0.8765\n",
      "Epoch 18/100\n",
      "438/438 [==============================] - 0s 731us/step - loss: 0.2993 - accuracy: 0.8752\n",
      "Epoch 19/100\n",
      "438/438 [==============================] - 0s 791us/step - loss: 0.2968 - accuracy: 0.8762\n",
      "Epoch 20/100\n",
      "438/438 [==============================] - 0s 758us/step - loss: 0.2954 - accuracy: 0.8795\n",
      "Epoch 21/100\n",
      "438/438 [==============================] - 0s 658us/step - loss: 0.2834 - accuracy: 0.8843\n",
      "Epoch 22/100\n",
      "438/438 [==============================] - 0s 638us/step - loss: 0.2834 - accuracy: 0.8821\n",
      "Epoch 23/100\n",
      "438/438 [==============================] - 0s 807us/step - loss: 0.2908 - accuracy: 0.8794\n",
      "Epoch 24/100\n",
      "438/438 [==============================] - 0s 687us/step - loss: 0.2812 - accuracy: 0.8843\n",
      "Epoch 25/100\n",
      "438/438 [==============================] - 0s 771us/step - loss: 0.2708 - accuracy: 0.8899\n",
      "Epoch 26/100\n",
      "438/438 [==============================] - 0s 634us/step - loss: 0.2847 - accuracy: 0.8861\n",
      "Epoch 27/100\n",
      "438/438 [==============================] - 0s 641us/step - loss: 0.2800 - accuracy: 0.8845\n",
      "Epoch 28/100\n",
      "438/438 [==============================] - 0s 619us/step - loss: 0.2758 - accuracy: 0.8846\n",
      "Epoch 29/100\n",
      "438/438 [==============================] - 0s 623us/step - loss: 0.2713 - accuracy: 0.8864\n",
      "Epoch 30/100\n",
      "438/438 [==============================] - 0s 642us/step - loss: 0.2694 - accuracy: 0.8901\n",
      "Epoch 31/100\n",
      "438/438 [==============================] - 0s 659us/step - loss: 0.2786 - accuracy: 0.8815\n",
      "Epoch 32/100\n",
      "438/438 [==============================] - 0s 659us/step - loss: 0.2749 - accuracy: 0.8870\n",
      "Epoch 33/100\n",
      "438/438 [==============================] - 0s 779us/step - loss: 0.2666 - accuracy: 0.8859\n",
      "Epoch 34/100\n",
      "438/438 [==============================] - 0s 725us/step - loss: 0.2696 - accuracy: 0.8844\n",
      "Epoch 35/100\n",
      "438/438 [==============================] - 0s 627us/step - loss: 0.2744 - accuracy: 0.8822\n",
      "Epoch 36/100\n",
      "438/438 [==============================] - 0s 620us/step - loss: 0.2657 - accuracy: 0.8871\n",
      "Epoch 37/100\n",
      "438/438 [==============================] - 0s 622us/step - loss: 0.2654 - accuracy: 0.8884\n",
      "Epoch 38/100\n",
      "438/438 [==============================] - 0s 617us/step - loss: 0.2703 - accuracy: 0.8851\n",
      "Epoch 39/100\n",
      "438/438 [==============================] - 0s 616us/step - loss: 0.2665 - accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "438/438 [==============================] - 0s 826us/step - loss: 0.2742 - accuracy: 0.8849\n",
      "Epoch 41/100\n",
      "438/438 [==============================] - 0s 911us/step - loss: 0.2545 - accuracy: 0.8925\n",
      "Epoch 42/100\n",
      "438/438 [==============================] - 0s 772us/step - loss: 0.2656 - accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "438/438 [==============================] - 0s 632us/step - loss: 0.2577 - accuracy: 0.8919\n",
      "Epoch 44/100\n",
      "438/438 [==============================] - 0s 641us/step - loss: 0.2626 - accuracy: 0.8894\n",
      "Epoch 45/100\n",
      "438/438 [==============================] - 0s 638us/step - loss: 0.2536 - accuracy: 0.8931\n",
      "Epoch 46/100\n",
      "438/438 [==============================] - 0s 843us/step - loss: 0.2528 - accuracy: 0.8969\n",
      "Epoch 47/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.8948\n",
      "Epoch 48/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2543 - accuracy: 0.8976\n",
      "Epoch 49/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2623 - accuracy: 0.8912\n",
      "Epoch 50/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2480 - accuracy: 0.9012\n",
      "Epoch 51/100\n",
      "438/438 [==============================] - 0s 856us/step - loss: 0.2510 - accuracy: 0.8945\n",
      "Epoch 52/100\n",
      "438/438 [==============================] - 0s 693us/step - loss: 0.2455 - accuracy: 0.8972\n",
      "Epoch 53/100\n",
      "438/438 [==============================] - 0s 621us/step - loss: 0.2462 - accuracy: 0.8983\n",
      "Epoch 54/100\n",
      "438/438 [==============================] - 0s 622us/step - loss: 0.2496 - accuracy: 0.8981\n",
      "Epoch 55/100\n",
      "438/438 [==============================] - 0s 634us/step - loss: 0.2476 - accuracy: 0.8948\n",
      "Epoch 56/100\n",
      "438/438 [==============================] - 0s 624us/step - loss: 0.2492 - accuracy: 0.8971\n",
      "Epoch 57/100\n",
      "438/438 [==============================] - 0s 623us/step - loss: 0.2408 - accuracy: 0.8984\n",
      "Epoch 58/100\n",
      "438/438 [==============================] - 0s 628us/step - loss: 0.2514 - accuracy: 0.8961\n",
      "Epoch 59/100\n",
      "438/438 [==============================] - 0s 628us/step - loss: 0.2435 - accuracy: 0.8986\n",
      "Epoch 60/100\n",
      "438/438 [==============================] - 0s 617us/step - loss: 0.2475 - accuracy: 0.8934\n",
      "Epoch 61/100\n",
      "438/438 [==============================] - 0s 635us/step - loss: 0.2399 - accuracy: 0.9009\n",
      "Epoch 62/100\n",
      "438/438 [==============================] - 0s 624us/step - loss: 0.2426 - accuracy: 0.8994\n",
      "Epoch 63/100\n",
      "438/438 [==============================] - 0s 729us/step - loss: 0.2495 - accuracy: 0.8921\n",
      "Epoch 64/100\n",
      "438/438 [==============================] - 0s 707us/step - loss: 0.2380 - accuracy: 0.9025\n",
      "Epoch 65/100\n",
      "438/438 [==============================] - 0s 613us/step - loss: 0.2413 - accuracy: 0.8962\n",
      "Epoch 66/100\n",
      "438/438 [==============================] - 0s 623us/step - loss: 0.2395 - accuracy: 0.8982\n",
      "Epoch 67/100\n",
      "438/438 [==============================] - 0s 617us/step - loss: 0.2350 - accuracy: 0.9025\n",
      "Epoch 68/100\n",
      "438/438 [==============================] - 0s 723us/step - loss: 0.2414 - accuracy: 0.9003\n",
      "Epoch 69/100\n",
      "438/438 [==============================] - 0s 880us/step - loss: 0.2326 - accuracy: 0.9053\n",
      "Epoch 70/100\n",
      "438/438 [==============================] - 0s 818us/step - loss: 0.2322 - accuracy: 0.9016\n",
      "Epoch 71/100\n",
      "438/438 [==============================] - 0s 696us/step - loss: 0.2394 - accuracy: 0.8983\n",
      "Epoch 72/100\n",
      "438/438 [==============================] - 0s 780us/step - loss: 0.2393 - accuracy: 0.9019\n",
      "Epoch 73/100\n",
      "438/438 [==============================] - 0s 632us/step - loss: 0.2366 - accuracy: 0.9041\n",
      "Epoch 74/100\n",
      "438/438 [==============================] - 0s 705us/step - loss: 0.2336 - accuracy: 0.9043\n",
      "Epoch 75/100\n",
      "438/438 [==============================] - 0s 664us/step - loss: 0.2317 - accuracy: 0.9012\n",
      "Epoch 76/100\n",
      "438/438 [==============================] - 0s 818us/step - loss: 0.2346 - accuracy: 0.9023\n",
      "Epoch 77/100\n",
      "438/438 [==============================] - 0s 731us/step - loss: 0.2286 - accuracy: 0.9057\n",
      "Epoch 78/100\n",
      "438/438 [==============================] - 0s 953us/step - loss: 0.2274 - accuracy: 0.9052\n",
      "Epoch 79/100\n",
      "438/438 [==============================] - 0s 907us/step - loss: 0.2315 - accuracy: 0.9040\n",
      "Epoch 80/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.9037\n",
      "Epoch 81/100\n",
      "438/438 [==============================] - 0s 682us/step - loss: 0.2295 - accuracy: 0.9042\n",
      "Epoch 82/100\n",
      "438/438 [==============================] - 0s 625us/step - loss: 0.2214 - accuracy: 0.9091\n",
      "Epoch 83/100\n",
      "438/438 [==============================] - 0s 642us/step - loss: 0.2269 - accuracy: 0.9032\n",
      "Epoch 84/100\n",
      "438/438 [==============================] - 0s 623us/step - loss: 0.2201 - accuracy: 0.9061\n",
      "Epoch 85/100\n",
      "438/438 [==============================] - 0s 627us/step - loss: 0.2253 - accuracy: 0.9068\n",
      "Epoch 86/100\n",
      "438/438 [==============================] - 0s 632us/step - loss: 0.2233 - accuracy: 0.9061\n",
      "Epoch 87/100\n",
      "438/438 [==============================] - 0s 626us/step - loss: 0.2292 - accuracy: 0.9050\n",
      "Epoch 88/100\n",
      "438/438 [==============================] - 0s 707us/step - loss: 0.2229 - accuracy: 0.9086\n",
      "Epoch 89/100\n",
      "438/438 [==============================] - 0s 687us/step - loss: 0.2274 - accuracy: 0.9062\n",
      "Epoch 90/100\n",
      "438/438 [==============================] - 0s 652us/step - loss: 0.2197 - accuracy: 0.9070\n",
      "Epoch 91/100\n",
      "438/438 [==============================] - 0s 682us/step - loss: 0.2225 - accuracy: 0.9050\n",
      "Epoch 92/100\n",
      "438/438 [==============================] - 0s 693us/step - loss: 0.2196 - accuracy: 0.9091\n",
      "Epoch 93/100\n",
      "438/438 [==============================] - 0s 688us/step - loss: 0.2148 - accuracy: 0.9087\n",
      "Epoch 94/100\n",
      "438/438 [==============================] - 0s 682us/step - loss: 0.2150 - accuracy: 0.9143\n",
      "Epoch 95/100\n",
      "438/438 [==============================] - 0s 878us/step - loss: 0.2145 - accuracy: 0.9110\n",
      "Epoch 96/100\n",
      "438/438 [==============================] - 0s 844us/step - loss: 0.2125 - accuracy: 0.9118\n",
      "Epoch 97/100\n",
      "438/438 [==============================] - 0s 656us/step - loss: 0.2143 - accuracy: 0.9124\n",
      "Epoch 98/100\n",
      "438/438 [==============================] - 0s 643us/step - loss: 0.2203 - accuracy: 0.9125\n",
      "Epoch 99/100\n",
      "438/438 [==============================] - 0s 676us/step - loss: 0.2148 - accuracy: 0.9110\n",
      "Epoch 100/100\n",
      "438/438 [==============================] - 0s 639us/step - loss: 0.2155 - accuracy: 0.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb4af9b7d50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = histo_counts.T\n",
    "\n",
    "# XX = np.array([XX[i,:] for i in range(Nexamples)])\n",
    "\n",
    "# XX = F\n",
    "Ntrain = int(Nexamples*0.7)\n",
    "\n",
    "print(XX.shape)\n",
    "train_images = XX[0:Ntrain,:]\n",
    "test_images  = XX[Ntrain+1:,:]\n",
    "train_labels = Y[0:Ntrain]\n",
    "test_labels  = Y[Ntrain+1:]\n",
    "\n",
    "# train_images.shape\n",
    "train_images = train_images/Nsamples\n",
    "test_images = test_images/Nsamples\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape = (1,100)),\n",
    "    keras.layers.Dense(300, activation=tf.nn.relu , input_shape = (Nbins,)),\n",
    "#     keras.layers.Dense(Nbins,activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(10,activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(2,activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 658us/step - loss: 0.2848 - accuracy: 0.8798\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Unimodal   Actual: Unimodal \n",
      "[0.05087383 0.9491262 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "\n",
    "peaks = ['Bimodal', 'Unimodal']\n",
    "\n",
    "# k = 17\n",
    "k = 17\n",
    "print(f\"Prediction: {peaks[np.argmax(predictions[k])]}   Actual: {peaks[int(test_labels[k])]} \")\n",
    "\n",
    "\n",
    "\n",
    "_=plt.bar(bincenters, test_images[k],0.1)\n",
    "print(predictions[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.948273851295081"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getSarleIndex(bincenters,train_images[1],10)\n",
    "getKurt(bincenters,train_images[100],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bincenters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
